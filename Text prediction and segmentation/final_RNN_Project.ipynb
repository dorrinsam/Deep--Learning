{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fc510cd",
      "metadata": {
        "id": "7fc510cd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import pickle\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5bdeaf8",
      "metadata": {
        "id": "d5bdeaf8"
      },
      "outputs": [],
      "source": [
        "colnames=['date','text', 't1', 't2', 't3', 't4', 't5','6']\n",
        "data = pd.read_csv('/content/twitter_sample_tweets.csv', names=colnames, header=None, on_bad_lines='skip')\n",
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66926602",
      "metadata": {
        "id": "66926602"
      },
      "outputs": [],
      "source": [
        "print(data['text'].head(10000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93f4f14c",
      "metadata": {
        "id": "93f4f14c"
      },
      "outputs": [],
      "source": [
        "import demoji\n",
        "data = data.head(10000).applymap(lambda x: demoji.replace(str(x),' '))\n",
        "print(data['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf8c08bf",
      "metadata": {
        "id": "bf8c08bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7c59c67-1ae1-42a2-a2fd-36ee26136194"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-292dd1c96a63>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  data['text'] = data['text'].str.replace('[#,@,&,/,:,~,`,!,$,%,^,*,(,),_,-,+,=,{,},|,\\,:,;,\",<,>,?,؟,/,↫]', ' ')\n",
            "<ipython-input-5-292dd1c96a63>:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  data['text'] = data['text'].str.replace('[', ' ')\n",
            "<ipython-input-5-292dd1c96a63>:3: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  data['text'] = data['text'].str.replace(']', ' ')\n",
            "<ipython-input-5-292dd1c96a63>:4: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  data['text'] = data['text'].str.replace('.', ' ')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2948707,)\n"
          ]
        }
      ],
      "source": [
        "data['text'] = data['text'].str.replace('[#,@,&,/,:,~,`,!,$,%,^,*,(,),_,-,+,=,{,},|,\\,:,;,\",<,>,?,؟,/,↫]', ' ')\n",
        "data['text'] = data['text'].str.replace('[', ' ')\n",
        "data['text'] = data['text'].str.replace(']', ' ')\n",
        "data['text'] = data['text'].str.replace('.', ' ')\n",
        "data['text'] = data['text'].str.replace(',', ' ')\n",
        "data['text'] = data['text'].str.replace('RT', ' ')\n",
        "data['text'] = data['text'].str.replace(' و ', ' ')\n",
        "data['text'] = data['text'].str.replace(' از ', ' ')\n",
        "data['text'] = data['text'].str.replace(' که ', ' ')\n",
        "data['text'] = data['text'].str.replace(' به ', ' ')\n",
        "data['text'] = data['text'].str.replace(' برای ', ' ')\n",
        "data['text'] = data['text'].str.replace(' از ', ' ')\n",
        "data['text'] = data['text'].str.replace(' چه ', ' ')\n",
        "data['text'] = data['text'].str.replace(' با ', ' ')\n",
        "data['text'] = data['text'].str.replace(' ای ', ' ')\n",
        "data['text'] = data['text'].str.replace(' بود ', ' ')\n",
        "data['text'] = data['text'].str.replace(' در ', ' ')\n",
        "data['text'] = data['text'].str.replace(' می ', ' ')\n",
        "data['text'] = data['text'].str.replace(' هم ', ' ')\n",
        "data['text'] = data['text'].str.replace(' ولی ', ' ')\n",
        "data['text'] = data['text'].str.replace(' هر ', ' ')\n",
        "data['text'] = data['text'].str.replace(' یه ', ' ')\n",
        "data['text'] = data['text'].str.replace(' را ', ' ')\n",
        "data['text'] = data['text'].str.replace(' رو ', ' ')\n",
        "data['text'] = data['text'].str.replace(' از ', ' ')\n",
        "data['text'] = data['text'].str.replace('  ', ' ')\n",
        "print(data['text'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfff2512",
      "metadata": {
        "id": "bfff2512"
      },
      "outputs": [],
      "source": [
        "data['text'] = data['text'].str.replace('\\d+', '')\n",
        "print(data['text'][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb85888c",
      "metadata": {
        "id": "fb85888c"
      },
      "outputs": [],
      "source": [
        "with open('/content/sample.txt', 'w' ,encoding=\"utf-8\") as f:\n",
        "    dfAsString = str(data['text'].to_list())\n",
        "    print(len(dfAsString))\n",
        "    f.write(dfAsString)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2371749",
      "metadata": {
        "id": "d2371749",
        "outputId": "6a136b57-2067-4612-b3ea-f63dbf55438c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "file = open(\"/content/sample.txt\", \"r\", encoding = \"utf8\")\n",
        "lines = []\n",
        "for i in file:\n",
        "    lines.append(i)\n",
        "print(lines)\n",
        "data = \"\"\n",
        "for i in lines:\n",
        "    data = ' '. join(lines)\n",
        "data = data.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '').replace('“','').replace('”','')  #new line, carriage return, unicode character --> replace by space\n",
        "data = data.split()\n",
        "data = ' '.join(data)\n",
        "print(len(data))\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3343438a",
      "metadata": {
        "id": "3343438a"
      },
      "outputs": [],
      "source": [
        "print(len(data))\n",
        "print(data[10])\n",
        "data = data.replace(\"'\", ' ')\n",
        "import re\n",
        "data = re.sub(r'\\s*[A-Za-z]+\\b', '' , data)\n",
        "print(data)\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([data])\n",
        "print(data[10])\n",
        "#print(len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3537328",
      "metadata": {
        "id": "e3537328"
      },
      "outputs": [],
      "source": [
        "pickle.dump(tokenizer, open('token.pkl', 'wb'))\n",
        "seq = tokenizer.texts_to_sequences([data])[0]\n",
        "print(seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "089d7aa3",
      "metadata": {
        "id": "089d7aa3"
      },
      "outputs": [],
      "source": [
        "size = len(tokenizer.word_index) + 1\n",
        "print(len(tokenizer.word_index))\n",
        "\n",
        "print(tokenizer.word_index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9231463e",
      "metadata": {
        "id": "9231463e"
      },
      "outputs": [],
      "source": [
        "sequences = []\n",
        "\n",
        "for i in range(3, len(seq)):\n",
        "    words = seq[i-3:i+1]\n",
        "    sequences.append(words)\n",
        "\n",
        "print(\"Length of sequences are: \", len(sequences))\n",
        "sequences = np.array(sequences)\n",
        "sequences[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85238924",
      "metadata": {
        "id": "85238924"
      },
      "outputs": [],
      "source": [
        "x= []\n",
        "y = []\n",
        "for i in sequences:\n",
        "    x.append(i[0:3])\n",
        "    y.append(i[3])\n",
        "x = np.array(x)\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "437a838a",
      "metadata": {
        "id": "437a838a"
      },
      "outputs": [],
      "source": [
        "print(\"Data: \", x[:10])\n",
        "print(\"Response: \", y[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da355b50",
      "metadata": {
        "id": "da355b50"
      },
      "outputs": [],
      "source": [
        "y = to_categorical(y, num_classes=size)\n",
        "y[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40e44feb",
      "metadata": {
        "id": "40e44feb"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(size, 10, input_length=3))\n",
        "model.add(LSTM(1000, return_sequences=True))\n",
        "model.add(LSTM(1000))\n",
        "model.add(Dense(1000, activation=\"relu\"))\n",
        "model.add(Dense(size, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7d2082b",
      "metadata": {
        "id": "d7d2082b",
        "outputId": "2789ba6b-b777-49e4-f78c-5ff6b7098b9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 3, 10)             263400    \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 3, 1000)           4044000   \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 1000)              8004000   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1000)              1001000   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 26340)             26366340  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 39,678,740\n",
            "Trainable params: 39,678,740\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "593807b7",
      "metadata": {
        "id": "593807b7",
        "outputId": "fdb5ee3f-5dd4-49a8-d8f3-999edec15f87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "2349/2349 [==============================] - ETA: 0s - loss: 8.5608\n",
            "Epoch 1: loss improved from inf to 8.56079, saving model to next_words.h5\n",
            "2349/2349 [==============================] - 787s 333ms/step - loss: 8.5608\n",
            "Epoch 2/20\n",
            "2349/2349 [==============================] - ETA: 0s - loss: 8.1240\n",
            "Epoch 2: loss improved from 8.56079 to 8.12396, saving model to next_words.h5\n",
            "2349/2349 [==============================] - 787s 335ms/step - loss: 8.1240\n",
            "Epoch 3/20\n",
            "2349/2349 [==============================] - ETA: 0s - loss: 7.6308\n",
            "Epoch 3: loss improved from 8.12396 to 7.63080, saving model to next_words.h5\n",
            "2349/2349 [==============================] - 800s 340ms/step - loss: 7.6308\n",
            "Epoch 4/20\n",
            "2349/2349 [==============================] - ETA: 0s - loss: 7.0223\n",
            "Epoch 4: loss improved from 7.63080 to 7.02230, saving model to next_words.h5\n",
            "2349/2349 [==============================] - 823s 351ms/step - loss: 7.0223\n",
            "Epoch 5/20\n",
            "2349/2349 [==============================] - ETA: 0s - loss: 6.3833\n",
            "Epoch 5: loss improved from 7.02230 to 6.38326, saving model to next_words.h5\n",
            "2349/2349 [==============================] - 780s 332ms/step - loss: 6.3833\n",
            "Epoch 6/20\n",
            "2349/2349 [==============================] - ETA: 0s - loss: 5.7401\n",
            "Epoch 6: loss improved from 6.38326 to 5.74014, saving model to next_words.h5\n",
            "2349/2349 [==============================] - 782s 333ms/step - loss: 5.7401\n",
            "Epoch 7/20\n",
            "2349/2349 [==============================] - ETA: 0s - loss: 5.1137\n",
            "Epoch 7: loss improved from 5.74014 to 5.11372, saving model to next_words.h5\n",
            "2349/2349 [==============================] - 765s 326ms/step - loss: 5.1137\n",
            "Epoch 8/20\n",
            "2349/2349 [==============================] - ETA: 0s - loss: 4.4969\n",
            "Epoch 8: loss improved from 5.11372 to 4.49693, saving model to next_words.h5\n",
            "2349/2349 [==============================] - 784s 334ms/step - loss: 4.4969\n",
            "Epoch 9/20\n",
            "2349/2349 [==============================] - ETA: 0s - loss: 3.9067\n",
            "Epoch 9: loss improved from 4.49693 to 3.90669, saving model to next_words.h5\n",
            "2349/2349 [==============================] - 782s 333ms/step - loss: 3.9067\n",
            "Epoch 10/20\n",
            " 303/2349 [==>...........................] - ETA: 11:13 - loss: 3.2212"
          ]
        }
      ],
      "source": [
        "checkpoint = ModelCheckpoint(\"words.h5\", monitor='loss', verbose=1, save_best_only=True)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001))\n",
        "model.fit(x, y, epochs=20, batch_size=64, callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3ba1fed",
      "metadata": {
        "id": "c3ba1fed"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "model = load_model('words.h5')\n",
        "tokenizer = pickle.load(open('token.pkl', 'rb'))\n",
        "\n",
        "def Predict(model, tokenizer, text):\n",
        "  sequence = tokenizer.texts_to_sequences([text])\n",
        "\n",
        "  if len(sequence[0]) < 3:\n",
        "\n",
        "    sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=3)\n",
        "  else:\n",
        "    sequence = np.array(sequence)\n",
        "\n",
        "  preds = np.argmax(model.predict(sequence))\n",
        "  predicted_word = \"\"\n",
        "\n",
        "  for key, value in tokenizer.word_index.items():\n",
        "    if value == preds:\n",
        "      predicted_word = key\n",
        "      break\n",
        "\n",
        "  print(predicted_word)\n",
        "  return predicted_word\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a1e18bc",
      "metadata": {
        "id": "7a1e18bc"
      },
      "outputs": [],
      "source": [
        "while(True):\n",
        "  text = input(\"Enter your line: \")\n",
        "\n",
        "  if text == \"0\":\n",
        "      print(\"Execution completed.....\")\n",
        "      break\n",
        "\n",
        "  else:\n",
        "      try:\n",
        "          text = text.split(\" \")\n",
        "          text = text[-3:]\n",
        "          print(text)\n",
        "\n",
        "          Predict(model, tokenizer, text)\n",
        "\n",
        "      except Exception as e:\n",
        "        print(\"Error occurred: \",e)\n",
        "        continue\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}